{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Learning (SSL)\n",
    "\n",
    "\n",
    "SSL studies how to learn from both labeled and unlabeled data, which can be useful when data is abundant but the resources to label them are limited.\n",
    "\n",
    "In this exercise, you will:\n",
    "\n",
    "* Given a simulated dataset with both labeled and unlabeled data, build a similarity graph and use the Harmonic Function Solution (HSF) to predict the labels of the unlabeled data;\n",
    "* Use HSF for face recognition, given a fixed dataset;\n",
    "* Implement an online version of HSF to label images as they appear in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Harmonic Function Solution\n",
    "\n",
    "Let $G = (V, E)$ be a weighted undirected graph where $V = \\{x_1, \\ldots, x_n \\}$ is the vertex set and $E$ is the edge set. Each edge $e_{ij} \\in E$ has a weight $w_{ij}$ and, if there is no edge between $x_i$ and $x_j$, then $w_{ij}=0$.\n",
    "\n",
    "Let $|V| = n$ be the total number of nodes. Only a subset of the nodes $S \\subset V$ with cardinality $|S| = l$ is labeled, and the remaining $u = n - l$ nodes are placed in the subset $T = V \\setminus S$. \n",
    "\n",
    "Our goal is to predict the labels of the vertices in $T$ using the structure of the graph. Since we believe that nodes close in the graph should have similar labels, we would like to have each node surrounded by a majority of nodes with the same label. In order to do so, we impose that the labeling vector $f \\in \\mathbb{R}^n$ must be an **harmonic function** on the graph, that is:\n",
    "\n",
    "$$\n",
    "f_i = \\frac{\\sum_{j} w_{ij} f_j}{\\sum_{j} w_{ij}},  \\forall i \\in T\n",
    "$$\n",
    "\n",
    "One interpretation for this constraint is that $w_{ij}$ represents the tendency of moving from node $x_i$ to node $x_j$, the stationary distribution of the transition matrix $P(j|i) = \\tfrac{w_{ij}}{\\sum_{k} w_{ik}}$  is a valid solution to our problem. \n",
    "\n",
    "### Hard HFS\n",
    "\n",
    "It can be shown that $f$ is harmonic if and only if $(Lf)_T = 0$, where $(Lf)_T$ is the vector containing the values of $Lf$ for the nodes in the set $T$, and $L$ is the graph Laplacian. \n",
    "\n",
    "Hence, the harmonic function solution to the SSL problem is the solution to the following optimization problem:\n",
    "\n",
    "$$\n",
    "\\min_{f \\in \\mathbb{R}^n}  f^T L f  \n",
    "\\quad \\text{s.t} \\quad\n",
    "y_i = f(x_i) \\quad \\forall x_i \\in S\n",
    "$$\n",
    "where $y_i$ are the labels available for the vertices $x_i \\in S$. This gives us:\n",
    "\n",
    "$$\n",
    "f_T = L_{TT}^{-1}(W_{TS}f_S) = - L_{TT}^{-1}(L_{TS}f_S) \n",
    "$$\n",
    "\n",
    "### Soft HFS\n",
    "\n",
    "If the labels are noisy, we might need to replace the \"hard\" constraint of the optimization problem above by a \"soft\" constraint. Let $C$ be a diagonal matrix such that $C_{ii} = c_l$ for labeled examples and $C_{ii} = c_u$ otherwise. Also, define $y_i = 0$ for unlabeled examples, that is, for $x_i \\in T$. \n",
    "\n",
    "The soft HFS objective function is\n",
    "\n",
    "$$\n",
    "\\min_{f\\in\\mathbb{R}^n} (f-y)^T C (f-y) + f^T L f\n",
    "$$\n",
    "whose solution is \n",
    "\n",
    "$$\n",
    "f^* = (C^{-1}L+I)^{-1}y\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Implement hard and soft HFS in the function `compute_hfs`. Complete the function `two_moons_hfs` to test your implementation using the datasets `data_2moons_hfs.mat` and `data_2moons_hfs_large.mat`.\n",
    "\n",
    "\n",
    "* Tips: \n",
    "    * Don't forget to choose well the parameters to build the graph and its Laplacian.\n",
    "    * You can use the functions `build_laplacian_regularized` and `build_similarity_graph`. The function `mask_labels` is used to chose how many labels are revealed.\n",
    "    * Be careful: the labels are revealed randomly, and each random realization can have different results! Check how the `seed` parameter works.\n",
    "    * Introduce noisy labels to compare hard and soft HFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.spatial.distance as sd\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "from helper import build_similarity_graph, label_noise\n",
    "from helper import build_laplacian, build_laplacian_regularized\n",
    "from helper import plot_classification\n",
    "from helper import mask_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define parameters for HFS\n",
    "\"\"\"\n",
    "params = {}\n",
    "\n",
    "# regularization parameter (gamma)\n",
    "params['laplacian_regularization'] = 0.0\n",
    "\n",
    "# the sigma value for the exponential (similarity) function, already squared\n",
    "params['var'] = 1.0\n",
    "\n",
    "# Threshold eps for epsilon graphs\n",
    "params['eps'] = None\n",
    "\n",
    "# Number of neighbours k for k-nn. If zero, use epsilon-graph\n",
    "params['k'] = None\n",
    "\n",
    "# String selecting which version of the laplacian matrix to construct.\n",
    "# 'unn':  unnormalized, 'sym': symmetric normalization, 'rw':  random-walk normalization \n",
    "params['laplacian_normalization'] = 'unn'\n",
    "\n",
    "# Coefficients for C matrix for soft HFS\n",
    "params['c_l'] = None\n",
    "params['c_u'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hfs(L, Y, soft=False, **params):\n",
    "    \"\"\"\n",
    "    TO BE COMPLETED\n",
    "\n",
    "    Function to perform HFS (hard or soft!).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    L : array\n",
    "        Graph Laplacian, (n x n) matrix (regularized or not)\n",
    "    Y : array\n",
    "        (n, ) array with nodes labels [0, 1, ... , num_classes] (0 is unlabeled)\n",
    "    soft : bool\n",
    "        If True, compute soft HFS. Otherwise, compute hard HFS.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        Labels, class assignments for each of the n nodes\n",
    "    \"\"\"\n",
    "\n",
    "    num_samples = L.shape[0]\n",
    "    Cl = np.unique(Y)\n",
    "    num_classes = len(Cl)-1\n",
    "\n",
    "    \"\"\"\n",
    "    Build the vectors:\n",
    "    y = (n x num_classes) target vector \n",
    "    l_idx = shape (l,) vector with indices of labeled nodes\n",
    "    u_idx = shape (u,) vector with indices of unlabeled nodes\n",
    "    \"\"\"\n",
    "    # ...\n",
    "    \n",
    "    if not soft:    \n",
    "        \"\"\"\n",
    "        Compute hard HFS.  \n",
    "\n",
    "        f_l = solution for labeled data. \n",
    "        f_u = solution for unlabeled data\n",
    "        f   = solution for all data\n",
    "        \"\"\"\n",
    "        f_l = None\n",
    "        f_u = None\n",
    "        f = None\n",
    "    \n",
    "        # ...\n",
    "\n",
    "    else:\n",
    "        \"\"\"\n",
    "        Compute soft HFS.\n",
    "        f = harmonic function solution \n",
    "        C = (n x n) diagonal matrix with c_l for labeled samples and c_u otherwise    \n",
    "        \"\"\"\n",
    "        f = None\n",
    "        C = None\n",
    "        # ...\n",
    "\n",
    "    \"\"\"\n",
    "    return the labels assignment from the hfs solution, and the solution f\n",
    "    labels: (n x 1) class assignments [1,2,...,num_classes]    \n",
    "    f : harmonic function solution\n",
    "    \"\"\"\n",
    "    return labels, f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_moons_hfs(l=4, l_noisy=1, soft=False, dataset='data_2moons_hfs.mat', plot=True, seed=None, **params):\n",
    "    \"\"\"    \n",
    "    TO BE COMPLETED.\n",
    "\n",
    "    HFS for two_moons data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    l : int\n",
    "        Number of labeled (unmasked) nodes provided to the HFS algorithm.\n",
    "    l_noisy : int\n",
    "        Number of *noisy* labels to introduce.\n",
    "    soft : bool\n",
    "        If true, use soft HFS, otherwise use hard HFS\n",
    "    dataset : {'data_2moons_hfs.mat' or 'data_2moons_hfs_large.mat'}\n",
    "        Which dataset to use.\n",
    "    plot : bool\n",
    "        If True, show plots\n",
    "    seed : int\n",
    "        If not None, set global numpy seed before choosing labels to reveal.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # Load the data. At home, try to use the larger dataset.    \n",
    "    in_data = loadmat(os.path.join('data', dataset))\n",
    "    X = in_data['X']\n",
    "    Y = np.array(in_data['Y'].squeeze(), dtype=np.uint32)\n",
    "\n",
    "    # infer number of labels from samples\n",
    "    num_samples = np.size(Y, 0)\n",
    "    unique_classes = np.unique(Y)\n",
    "    num_classes = len(unique_classes)\n",
    "    \n",
    "    # mask labels\n",
    "    Y_masked = mask_labels(Y, l)\n",
    "    assert len(np.unique(Y_masked)) > 2, \"only one class in training data!\"\n",
    "    # introduce noise\n",
    "    noise_indices = np.where(Y_masked == 0)[0]\n",
    "    np.random.shuffle(noise_indices)\n",
    "    noise_indices = noise_indices[:l_noisy]\n",
    "    Y_masked[noise_indices] = np.random.choice(unique_classes, l_noisy)\n",
    "\n",
    "    \"\"\"\n",
    "    compute hfs solution using either soft_hfs or hard_hfs\n",
    "    \"\"\"\n",
    "    # Build graph Laplacian using the parameters:\n",
    "    # params['laplacian_regularization'], params['var'], params['eps'], \n",
    "    # params['k'] and params['laplacian_normalization'].\n",
    "    \n",
    "    # L = ...\n",
    "\n",
    "    labels, f = compute_hfs(L, Y_masked, soft, **params)\n",
    "\n",
    "    # Visualize results\n",
    "    if plot:\n",
    "        plot_classification(X, Y, Y_masked, noise_indices, labels, params['var'], params['eps'], params['k'])\n",
    "    accuracy = np.mean(labels == np.squeeze(Y))\n",
    "    print(f\"Soft={soft}, Accuracy={accuracy}\")\n",
    "    return X, Y, labels, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.1 - Report the accuracy you obtained for `data_2moons_hfs.mat` dataset using hard HFS, when l=10 and l_noisy=0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'L' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d01b7e445cc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m X, Y, hard_labels, hard_accuracy = two_moons_hfs(l=10, l_noisy=0, soft=False, dataset='data_2moons_hfs.mat',\n\u001b[0;32m----> 3\u001b[0;31m                                                  plot=True, seed=seed, **params)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-71b6033f68d6>\u001b[0m in \u001b[0;36mtwo_moons_hfs\u001b[0;34m(l, l_noisy, soft, dataset, plot, seed, **params)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# L = ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_hfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_masked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Visualize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'L' is not defined"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "X, Y, hard_labels, hard_accuracy = two_moons_hfs(l=10, l_noisy=0, soft=False, dataset='data_2moons_hfs.mat',\n",
    "                                                 plot=True, seed=seed, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2  - Using `data_2moons_hfs_large.mat`, run `two_moons_hfs` several times with l=4. What can go wrong?\n",
    "\n",
    "* Tips:\n",
    "    * When running `two_moons_hfs` several times, don't forget to set `seed=None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# for ii in range(20):\n",
    "#     X, Y, hard_labels, hard_accuracy = two_moons_hfs(l=4, l_noisy=0, soft=False, \n",
    "#                                                      dataset='data_2moons_hfs_large.mat',\n",
    "#                                                      plot=False, seed=None, **params)\n",
    "    \n",
    "mask_labels?  # check parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3 - Using `data_2moons_hfs.mat`, l=10 and l_noisy=5, compare hard HFS to soft HFS. Report the accuracy and comment the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing\n",
    "seed = 5  # To run several times with random outcomes, set seed=None. Otherwise, set a seed for reproducibility.\n",
    "plot = True \n",
    "dataset = 'data_2moons_hfs.mat' # Try also 'data_2moons_hfs_large.mat'\n",
    "\n",
    "X, Y, hard_labels, hard_accuracy = two_moons_hfs(l=10, l_noisy=5, soft=False, dataset=dataset,\n",
    "                                                 plot=plot, seed=seed, **params)\n",
    "X, Y, soft_labels, soft_accuracy = two_moons_hfs(l=10, l_noisy=5, soft=True, dataset=dataset,\n",
    "                                                 plot=plot, seed=seed, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Face recognition with HFS\n",
    "\n",
    "Now, we apply HFS to the task of face recognition, that is, our goal is to classify faces as belonging to different people. Since faces all share common features, it can be a good idea to leverage a large quantity of unlabeled data to improve classification accuracy. In this part of the exercise, you will:\n",
    "\n",
    "* Extract faces from the images using OpenCV for face detection, and use the same library to apply preprocessing steps;\n",
    "* Run HFS for classification.\n",
    "\n",
    "### Implementation\n",
    "\n",
    "Choose the hyperparameters and run HFS for face recognition, using both the small and large dataset. You can try to change the preprocessing steps (e.g. equalizeHist, GaussianBlur) applied to the images.\n",
    "\n",
    "**Important**: make sure your HFS code is able to handle more than two classes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1 - How did you manage to label more than two classes?\n",
    "\n",
    "### Question 2.2 - Report the best accuracy you obtained for both (small and augmented) datasets.\n",
    "\n",
    "* Tips:\n",
    "    * The small dataset (10 images per person) is loaded with `load_image_data`.\n",
    "    * Use `load_image_data_augmented` for the augmented dataset (50 images per person). \n",
    "\n",
    "### Question 2.3 - If the accuracy changes when using the augmented dataset, explain why. Does using additional data always increase the performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from load_images import load_image_data, plot_image_data\n",
    "from load_images import load_image_data_augmented, plot_image_data_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define parameters for face recognition with HFS\n",
    "\"\"\"\n",
    "params_face_rec = {}\n",
    "params_face_rec['laplacian_regularization'] = 1.0\n",
    "params_face_rec['var'] = 10000.0\n",
    "params_face_rec['eps'] = None\n",
    "params_face_rec['k'] = None\n",
    "params_face_rec['laplacian_normalization'] = 'unn'\n",
    "params_face_rec['c_l'] = None\n",
    "params_face_rec['c_u'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the images\n",
    "# You may try to change it and check the impact on the classification accuracy\n",
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : array\n",
    "        (width, height) array representing a grayscale image\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        (96, 96) preprocessed image\n",
    "    \"\"\"\n",
    "    output_frame_size = 96   # do not change the output frame size!\n",
    "    image = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "    image = cv2.equalizeHist(image)\n",
    "    image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    im = cv2.resize(image, (output_frame_size, output_frame_size)).astype(np.float)\n",
    "    im -= im.mean()\n",
    "    im /= im.max()\n",
    "    image = im\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 10 images per person\n",
    "np.random.seed(456)   # set seed, since labels are masked randomly\n",
    "images, labels, masked_labels = load_image_data(preprocess_image)\n",
    "\n",
    "# # 50 images per person\n",
    "# images_a, labels_a, masked_labels_a = load_image_data_augmented(preprocess_image)\n",
    "# plot_image_data_augmented(images_a)\n",
    "\n",
    "# Uncomment below if you want to visualize the images\n",
    "# plot_image_data(images)\n",
    "# print(images.shape)\n",
    "# print(masked_labels.reshape(-1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph Laplacian\n",
    "L = build_laplacian_regularized(images, \n",
    "                                params_face_rec['laplacian_regularization'], \n",
    "                                params_face_rec['var'], \n",
    "                                params_face_rec['eps'], \n",
    "                                params_face_rec['k'], \n",
    "                                params_face_rec['laplacian_normalization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  1.0\n",
      "[ 1.  2.  0.  0.  0.  6.  7.  8.  0.  0.  1.  2.  0.  4.  0.  0.  7.  0.\n",
      "  0.  0.  1.  0.  3.  0.  0.  0.  0.  0.  9.  0.  1.  0.  3.  0.  0.  6.\n",
      "  0.  0.  9. 10.  0.  0.  0.  4.  5.  6.  0.  8.  0.  0.  0.  0.  0.  4.\n",
      "  5.  0.  0.  0.  0.  0.  0.  2.  3.  0.  0.  0.  0.  0.  9. 10.  0.  0.\n",
      "  0.  0.  5.  6.  7.  0.  0. 10.  0.  0.  0.  0.  5.  0.  0.  8.  9. 10.\n",
      "  0.  2.  3.  4.  0.  0.  7.  8.  0.  0.]\n",
      "[ 1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10  1  2  3  4\n",
      "  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8\n",
      "  9 10  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10  1  2\n",
      "  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6\n",
      "  7  8  9 10]\n",
      "[ 1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10  1  2  3  4\n",
      "  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8\n",
      "  9 10  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10  1  2\n",
      "  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6\n",
      "  7  8  9 10]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run HFS\n",
    "predicted_labels, f = compute_hfs(L, masked_labels, soft=True, **params_face_rec)\n",
    "accuracy = np.equal(predicted_labels, labels).mean()\n",
    "print(\"Accuracy = \", accuracy)\n",
    "\n",
    "print(masked_labels)\n",
    "print(predicted_labels)\n",
    "print(labels)\n",
    "# Visualize predicted vs true labels\n",
    "plt.subplot(121)\n",
    "plt.imshow(labels.reshape((-1, 10)))\n",
    "plt.subplot(122)\n",
    "plt.imshow(predicted_labels.reshape((-1, 10)))\n",
    "plt.title(\"Accuracy: {}\".format(accuracy))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Online SSL\n",
    "\n",
    "Now, instead of having all the data available at once, images will be received online: at each time $t$, a new image $x_t$ is observed and the algorithm has to output a label $y_t$. \n",
    "\n",
    "Use the function `create_user_profile` to capture a training set of labeled data (of your face and someone else). The faces will be preprocessed and saved in the folder `data/faces`. They will be loaded by `online_face_recognition`.\n",
    "\n",
    "\n",
    "### Implementation\n",
    "\n",
    "Choose the hyperparameters and complete the functions `online_ssl_update_centroids` and `online_ssl_compute_solution`. \n",
    "\n",
    "Modify your code to be able to disregard faces it cannot recognize.\n",
    "\n",
    "* Tips:\n",
    "    * You can use the functions `build_similarity_graph` and `build_laplacian`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1 - Attach to this notebook some of the resulting frames of online face recognition. \n",
    "\n",
    "* Tips: \n",
    "    * You can save the resulting frame and add it to the notebook in a markdown cell as `![title](picture.png)`\n",
    "    \n",
    "### Question 3.2 - What strategy did you use to label a face as unknown? Attach to this notebook an example of a unknown face being correctly labeled as unknown.\n",
    "\n",
    "* Tips\n",
    "    * If you identify a face as unknown, you can return `[(\"unknown\", score)]` from the function `online_ssl_compute_solution`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import sys\n",
    "from scipy.spatial import distance\n",
    "import scipy.io as sio\n",
    "\n",
    "from helper_online_ssl import create_user_profile, online_face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define parameters for face recognition with HFS\n",
    "\"\"\"\n",
    "params_online_ssl = {}\n",
    "params_online_ssl['laplacian_regularization'] = 1.0\n",
    "params_online_ssl['var'] = 10000.0\n",
    "params_online_ssl['eps'] = None\n",
    "params_online_ssl['k'] = None\n",
    "params_online_ssl['laplacian_normalization'] = 'unn'\n",
    "params_online_ssl['c_l'] = None\n",
    "params_online_ssl['c_u'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncrementalKCenters:\n",
    "    def __init__(self, labeled_faces, labels, label_names, max_num_centroids=50):\n",
    "        #  Number of labels\n",
    "        self.n_labels = max(labels)\n",
    "\n",
    "        #  Dimension of the input image\n",
    "        self.image_dimension = labeled_faces.shape[1]\n",
    "\n",
    "        #  Check input validity\n",
    "        assert (set(labels) == set(\n",
    "            range(1, 1 + self.n_labels))), \"Initially provided faces should be labeled in [1, max]\"\n",
    "        assert (len(labeled_faces) == len(labels)), \"Initial faces and initial labels are not of same size\"\n",
    "\n",
    "        #  Number of labelled faces\n",
    "        self.n_labeled_faces = len(labeled_faces)\n",
    "\n",
    "        # Model parameter : number of maximum stored centroids\n",
    "        self.max_num_centroids = max_num_centroids\n",
    "\n",
    "        # Model centroids (inital labeled faces). Shape = (number_of_centroids, dimension)\n",
    "        self.centroids = labeled_faces\n",
    "\n",
    "        # Centroids labels\n",
    "        self.Y = labels\n",
    "        \n",
    "        # Label names (= user names)\n",
    "        self.label_names = label_names\n",
    "\n",
    "        # Variables that are initialized in online_ssl_update_centroids()\n",
    "        self.centroids_distances = None\n",
    "        self.taboo = None\n",
    "        self.V = None\n",
    "        self.init = True\n",
    "\n",
    "        # index of x_t (initialized later)\n",
    "        self.last_face = None\n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Initialization after the first time that the maximum number of centroids is reached.\n",
    "        \"\"\"       \n",
    "        #  Compute the centroids distances\n",
    "        self.centroids_distances = distance.cdist(self.centroids, self.centroids)\n",
    "\n",
    "        #  set labeled nodes and self loops as infinitely distant, to avoid merging labeled centroids\n",
    "        np.fill_diagonal(self.centroids_distances, +np.Inf)\n",
    "        self.centroids_distances[0:self.n_labeled_faces, 0:self.n_labeled_faces] = +np.Inf\n",
    "\n",
    "        # put labeled nodes in the taboo list\n",
    "        self.taboo = np.array(range(self.centroids.shape[0])) < self.n_labeled_faces\n",
    "\n",
    "        # initialize multiplicity\n",
    "        self.V = np.ones(self.centroids.shape[0])\n",
    "\n",
    "\n",
    "    def online_ssl_update_centroids(self, face):\n",
    "        \"\"\"\n",
    "        TO BE COMPLETED\n",
    "\n",
    "        Update centroids, multiplicity vector V, labels Y.\n",
    "        \n",
    "        Note: In Y, set label to 0 for unlabeled faces.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        face : array\n",
    "            New sample\n",
    "        \n",
    "        Returns\n",
    "        --------\n",
    "        List with the scores for each possible label:\n",
    "            [(label_1, score_1), (label_2, score_2), ...]\n",
    "        \"\"\"\n",
    "\n",
    "        assert (self.image_dimension == len(face)), \"new image not of good size\"\n",
    "\n",
    "        # Case 1: maximum number of centroids has been reached.\n",
    "        if self.centroids.shape[0] >= self.max_num_centroids + 1:\n",
    "            if self.init:\n",
    "                #  Initialization after the first time that the maximum number of centroids is reached\n",
    "                self.initialize()\n",
    "                self.init = False\n",
    "            \"\"\"\n",
    "            Find c_rep and c_add following Algorithm 1.\n",
    "            \n",
    "            - c_1, c_2 = two closest centroids (minimum distance) such that at least one of them is not in self.taboo.\n",
    "            - c_rep = centroid in {c_1, c_2} that is in self.taboo. If none of them is in self.taboo, c_rep is the one\n",
    "                      with largest multiplicity.\n",
    "            - c_add = centroid in {c_1, c_2} that is not c_rep.\n",
    "            \"\"\"\n",
    "            c_rep, c_add = None, None\n",
    "\n",
    "            # ...\n",
    "\n",
    "            \"\"\"\n",
    "            Update data structures: self.centroids and self.V\n",
    "            \"\"\"\n",
    "            # ...\n",
    "\n",
    "            \"\"\"\n",
    "            Update the matrix containing the distances.\n",
    "            \"\"\"\n",
    "            dist_row = distance.cdist(np.array([self.centroids[c_add]]), self.centroids)[0]\n",
    "            dist_row[c_add] = +np.inf\n",
    "            self.centroids_distances[c_add, :] = dist_row\n",
    "            self.centroids_distances[:, c_add] = dist_row\n",
    "            self.last_face = c_add\n",
    "\n",
    "        # Case 2: create new centroid with face\n",
    "        # Remark: the multiplicities vector self.V is initialized in self.initialize()\n",
    "        else:\n",
    "            current_len = len(self.centroids)\n",
    "            self.Y = np.append(self.Y, 0)\n",
    "            self.centroids = np.vstack([self.centroids, face])\n",
    "\n",
    "    def online_ssl_compute_solution(self):\n",
    "        \"\"\"\n",
    "        TO BE COMPLETED.\n",
    "\n",
    "        Returns a prediction corresponding to self.last_face.\n",
    "        \"\"\"\n",
    "\n",
    "        # Multiplicity matrix\n",
    "        if self.init:\n",
    "            V = np.diag(np.ones(self.centroids.shape[0]))\n",
    "            self.last_face = self.centroids.shape[0] - 1\n",
    "        else:\n",
    "            V = np.diag(self.V)\n",
    "            \n",
    "        # Build quantized graph and its regularized Laplacian\n",
    "        \n",
    "        # W = ...\n",
    "        # L = ...\n",
    "        # Q = ...   # regularized Laplacian\n",
    "\n",
    "        # Compute the hard HFS solution f. \n",
    "        labels, f = compute_hfs(Q, self.Y, soft=False, **params_online_ssl)\n",
    "\n",
    "        # Return the score for each possible label\n",
    "        num_classes = len(np.unique(self.Y))-1 \n",
    "        label_scores = []\n",
    "        for ii in range(num_classes):\n",
    "            label = self.label_names[ii]\n",
    "            score = f[self.last_face, ii]\n",
    "            label_scores.append((label, score))\n",
    "        \n",
    "        # handle unknown faces\n",
    "        # ...\n",
    "\n",
    "        return label_scores\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile found with 0 images.\n",
      "Image 1 saved at data/faces/bob2/img_1.bmp\n"
     ]
    }
   ],
   "source": [
    "create_user_profile('bob2')         # choose your names here :)\n",
    "# create_user_profile('alice')\n",
    "# online_face_recognition(['bob', 'alice'], IncrementalKCenters, n_pictures=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.1 - You can now classify faces as either known (i.e. belong to a class) or unknown (i.e. belong to no class). How would you modify the algorithm to automatically learn to classify new classes? That is, how can you modify the algorithm so that faces that appear unfrequently are labeled as unknown, but once a specific face has been seen enough times it gets assigned an automatic label (e.g. AutoBob) and from that point it is treated as a new class. \n",
    "\n",
    "* Tips: \n",
    "    * Think back to the idea of incremental clustering as unsupervised classification\n",
    "    \n",
    "### Question 4.2 - In class we considered different kinds of metric for (semi) supervised learning. Looking at the face classification task, try to quantify how the offline-online, exact-quantized, and inductive-transductive axes influence each other. In particular given $l$ labeled faces, $u = N - l$ unlabeled faces, and $m$ extra/test faces design an experimental study to quantify these trade-offs, both in terms of transductive and inductive error, as well as online/batch error. Examples of combinations that can be used to study these axes are:\n",
    "* Supervised vs Semi-supervised\n",
    "    * A comparison between a supervised learner (of your choice) trained on the $l$ labeled faces and a semi-supervised learner (of your choice) trained on the $l + u$ labeled and unlabeled faces\n",
    "    * A comparison between a supervised learner (of your choice) trained on the $N$ labeled and unlabeled (you reveal everything here) faces and a semi-supervised learner (of your choice) trained on the $l + u$ labeled and unlabeled faces.\n",
    "* Inductive vs Transductive\n",
    "    * A comparison between a supervised learner (of your choice) trained on the $l$ labeled faces and a semi-supervised learner (of your choice) trained on the $l + u$ labeled and unlabeled faces evaluated on the $N$ revealed points and then on the $m$ unrevealed points.\n",
    "* Supervised vs Semi-supervised and Inductive vs Transductive\n",
    "    * A comparison between a supervised learner (of your choice) trained on the $N$ labeled and unlabeled (you reveal everything here) faces and a semi-supervised learner (of your choice) trained on the $l + u$ labeled and unlabeled faces, evaluated on the $N$ revealed points and then on the $m$ unrevealed points.\n",
    "* Online vs Batch\n",
    "    * A comparison between a supervised learner (of your choice) trained on the $N$ labeled faces and an online supervised learner (of your choice) trained revealing the $N$ labels one at a time\n",
    "* Exact vs Quantized\n",
    "    * A comparison between a semi-supervised learner (of your choice) trained on the $N$ labeled and unlabeled (you reveal everything here) faces using a certain memory budget, and the same learner with a constrained memory budget.\n",
    "* Exact vs Quantized and Online vs Batch and Inductive vs Transductive\n",
    "    * A comparison between a semi-supervised online learner (of your choice) trained with and without quantization, evaluated both on the $N$ faces revealed during training, and $m$ faces unrevealed. You can further compare the online performance of the learner against the performance of an \"hindsight\" learner that saw the labels all at once"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
